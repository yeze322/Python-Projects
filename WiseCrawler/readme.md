# Wise Crawler V2.0 #

主要修改部分——进一步封装了接口，相比前面的那个版本更加的好用

最重要的是代码组织变得更好

Crawlib.py为主要的库

WiseCrawler.py为运行示例

# 使用方法 #

在WiseCrawler.py中输入自己想要爬的网址

先不要设置start为1

先运行一下，看看生成的筛选文件中，URL是否符合你的过滤负责

不符合则修改过滤规则。

然后start=0即可运行

因为在windows下使用，没有修改成linux命令行模式，明天会修改

# 过滤规则说明 #

原来有 4 条过滤规则，现在将URL提取规则设置成了默认提取 href="[--]"中括号内的内容。

同时智能识别完整URL和相对路径的URL

依然提供的过滤规则接口整合成了一个 ——》 [ 包含关键词 , 排除关键词 ]

其中关键词也是一个列表、

示例：

rule1 = [['html','read'],[]]

rule2 = [['broadcast','CNN'],[]]

ruleset = [rule1,rule2]

ruleset即为传入的参数。

计划将输入形式修改为 +A -B 模式